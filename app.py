import streamlit as st
from PIL import Image, ImageOps
import numpy as np
import cv2
from io import BytesIO
from ultralytics import YOLO
import os
from rembg import remove
import torch
from diffusers import StableDiffusionInpaintPipeline
from PIL import Image
import time 

# from dotenv import load_dotenv
# load_dotenv() # .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°

# -----------------------------
# ì„¤ì •
# -----------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR, "models")

st.set_page_config(page_title="AI ì¦ëª…ì‚¬ì§„ ìƒì„±ê¸°", layout="centered")
st.title("ðŸ“¸ AI ì¦ëª…ì‚¬ì§„ ìƒì„±ê¸°")
st.markdown("ì‚¬ë§ê³¼ ë°˜ë ¤ë™ë¬¼ì˜ ì‚¬ì§„ì„ ì¦ëª…ì‚¬ì§„ìœ¼ë¡œ ìžë™ ë³€í™”í•´ë³´ì„¸ìš”!")

# -----------------------------
# ì‚¬ì´ë“œë°” ì„¤ì •
# -----------------------------
st.sidebar.header("âš™ï¸ ì„¤ì •")

st.sidebar.subheader("ðŸ“¦ ëª¨ë¸ ì„ íƒ")
model_choice = st.sidebar.selectbox("ëª¨ë¸ ì„ íƒ", ["ì‚¬ëžŒ (ê¸°ë³¸)", "dog-cat-detector"])


target = st.sidebar.selectbox("ëŒ€ìƒì„ ì„ íƒí•˜ì„¸ìš”", ["ì„ íƒí•˜ì„¸ìš”", "ì‚¬ëžŒ", "ê°•ì•„ì§€/ê³ ì–‘ì´"], index=0)
if target == "ì‚¬ëžŒ":
    gender = st.sidebar.radio("ì„±ë³„ì„ ì„ íƒí•˜ì„¸ìš”", ["ì—¬ìž", "ë‚¨ìž"])

bg_color = st.sidebar.selectbox("ë°°ê²½ ìƒ‰ìƒ ì„ íƒ", ["í°ìƒ‰", "íŒŒëž€ìƒ‰", "ë¯¼íŠ¸"])

st.sidebar.markdown("## ðŸ“„ ì¶”ê°€ ì •ë³´")
name = st.sidebar.text_input("ì´ë¦„ (ì„ íƒ)")
breed = st.sidebar.text_input("ì¢… / ì¶œìƒì¼ ë“± (ì„ íƒ)")

# -----------------------------
# íŒŒì¼ ì—…ë¡œë”
# -----------------------------
uploaded_file = None
if target:
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])
else:
    st.info("ðŸ“Œ ë¨¼ì € **ëŒ€ìƒì„ ì„ íƒ**í•˜ë©´ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•  ìˆ˜ ìžˆì–´ìš”!")

# -----------------------------
# ëª¨ë¸ ë¡œë“œ
# -----------------------------
@st.cache_resource
def load_model(model_choice):
    if model_choice == "dog-cat-detector":
        model_path = os.path.join(MODEL_DIR, "dog-cat-detector.pt")
    else:
        st.error("ì‚¬ëžŒ ëª¨ë¸ì€ ì•„ì§ ì§€ì›ë˜ì§€ ì•Šì•„ìš”.")
        return None

    if not os.path.exists(model_path):
        st.error(f"ëª¨ë¸ íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•Šì•„ìš”: {model_path}")
        return None

    return YOLO(model_path)  # ultralyticsì—ì„œ YOLO ëª¨ë¸ ë¡œë”©


@st.cache_resource
def load_inpainting_model():
    model_id = "runwayml/stable-diffusion-inpainting"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    pipe = StableDiffusionInpaintPipeline.from_pretrained(
        model_id,
        torch_dtype=torch.float16 if device == "cuda" else torch.float32
    )
    return pipe.to(device)

def add_border(image, border_size, border_color=(0, 0, 0)):
    if isinstance(image, Image.Image):
        image = np.array(image)
    bordered_image = cv2.copyMakeBorder(
        image, border_size, border_size, border_size, border_size,
        cv2.BORDER_CONSTANT, value=border_color
    )
    return Image.fromarray(bordered_image)

def display_result_section(original_img, result_img, target="ëŒ€ìƒ"):
    result_img_with_border = add_border(result_img, border_size=1)
    st.success(f"{target}ì˜ ì¦ëª…ì‚¬ì§„ ìƒì„± ì™„ë£Œ!")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("#### â¬…ï¸ Before")
        st.image(original_img, use_column_width=True)
    with col2:
        st.markdown("#### âž¡ï¸ After")
        st.image(result_img_with_border, use_column_width=True)

    buf = BytesIO()
    result_img_with_border.save(buf, format="PNG")
    st.download_button("ðŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ", data=buf.getvalue(), file_name="id_photo.png", mime="image/png")

# -----------------------------
# IOU ì¤‘ë³µ ë°•ìŠ¤ ì œê±°
# -----------------------------
# def non_max_suppression(boxes, iou_threshold=0.5):
#     if len(boxes) == 0:
#         return []

#     boxes = sorted(boxes, key=lambda x: (x[2] - x[0]) * (x[3] - x[1]), reverse=True)
#     selected_boxes = []

#     while boxes:
#         chosen_box = boxes.pop(0)
#         selected_boxes.append(chosen_box)

#         def iou(box1, box2):
#             x1, y1, x2, y2 = box1
#             x1_p, y1_p, x2_p, y2_p = box2
#             xi1, yi1 = max(x1, x1_p), max(y1, y1_p)
#             xi2, yi2 = min(x2, x2_p), min(y2, y2_p)
#             intersection = max(0, xi2 - xi1) * max(0, yi2 - yi1)
#             area1 = (x2 - x1) * (y2 - y1)
#             area2 = (x2_p - x1_p) * (y2_p - y1_p)
#             union = area1 + area2 - intersection
#             return intersection / union if union > 0 else 0

#         boxes = [box for box in boxes if iou(chosen_box, box) < iou_threshold]

#     return selected_boxes

# -----------------------------
# ê³µí†µ Inpainting í•¨ìˆ˜ (ë™ë¬¼, ì¸ê°„ í•´ë‹¹)
# -----------------------------

def generate_id_photo(cropped_face_image, prompt, output_filename="passport_photo.jpg"):
    from io import BytesIO

    # ë°°ê²½ ì œê±°
    no_bg_face = remove(cropped_face_image).convert("RGBA")
    # st.image(no_bg_face, caption="ë°°ê²½ ì œê±°ëœ ì–¼êµ´", use_container_width=True)

    # ë§ˆìŠ¤í¬ ìƒì„±
    init_image = no_bg_face.resize((512, 512))
    init_np = np.array(init_image)
    alpha_channel = init_np[:, :, 3]
    mask = np.where(alpha_channel == 0, 255, 0).astype(np.uint8)
    mask_image = Image.fromarray(mask).convert("L")
    # st.image(mask_image, caption="Inpainting ë§ˆìŠ¤í¬", use_container_width=True)

    # Inpainting ëª¨ë¸ ë¡œë“œ
    pipe = load_inpainting_model()
    progress_bar = st.progress(0)
    
    for percent_comp in range(0,100,5):
        time.sleep(0.05)
        progress_bar.progress(percent_comp)

    with st.spinner("ì´ë¯¸ì§€ ìƒì„± ì¤‘..."):
        result = pipe(
            prompt=prompt,
            image=init_image.convert("RGB"),
            mask_image=mask_image,
            strength=0.95,
            guidance_scale=7.5,
        )
        result_image = result.images[0]
        progress_bar.progress(100)

    # ê²°ê³¼ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ
    st.image(result_image, caption="ì¦ëª…ì‚¬ì§„ ê²°ê³¼", use_container_width=True)

    buf = BytesIO()
    result_image.save(buf, format="JPEG")
    st.download_button(
        label="ì¦ëª…ì‚¬ì§„ ë‹¤ìš´ë¡œë“œ",
        data=buf.getvalue(),
        file_name=output_filename,
        mime="image/jpeg"
    )


# -----------------------------
# ê°•ì•„ì§€/ê³ ì–‘ì´ ì–¼êµ´ ê°ì§€ ë° ì¦ëª…ì‚¬ì§„ ìƒì„±
# -----------------------------
def process_pet(image, model_choice):
    model = load_model(model_choice)
    if model is None:
        st.warning("ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    img_np = np.array(image)
    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

    with st.spinner("ë°˜ë ¤ë™ë¬¼ ì–¼êµ´ ì¸ì‹ ì¤‘... â³"):
        results = model.predict(source=img_bgr, save=False, verbose=False)
        boxes = results[0].boxes.xyxy.cpu().numpy().astype(int)

    if len(boxes) == 0:
        st.warning("ë°˜ë ¤ë™ë¬¼ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆì–´ìš” ðŸ˜¢")
        return

    st.markdown("### ðŸŸ© ì¸ì‹ëœ ë°˜ë ¤ë™ë¬¼ ì–¼êµ´ (ì„ íƒ ê°€ëŠ¥)")
    cropped_faces = []
    boxed_image = img_np.copy()

    for i, (x1, y1, x2, y2) in enumerate(boxes):
        box_width = x2 - x1
        desired_aspect = 3 / 4
        desired_crop_height = int(box_width / desired_aspect)

        new_y1 = y1
        new_y2 = min(y1 + desired_crop_height, img_np.shape[0])

        if new_y2 - new_y1 < 50:
            continue

        cv2.rectangle(boxed_image, (x1, new_y1), (x2, new_y2), (0, 255, 0), 2)
        cropped_faces.append(img_np[new_y1:new_y2, x1:x2])

    st.image(Image.fromarray(boxed_image), caption="ê°ì§€ëœ ì–¼êµ´", use_container_width=True)

    if len(cropped_faces) == 0:
        st.warning("ì–¼êµ´ ì¤‘ì‹¬ ì˜ì—­ì´ ë„ˆë¬´ ìž‘ì•„ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ìš”.")
        return

    selected_face = st.selectbox("ë³€í™˜í•  ì–¼êµ´ì„ ì„ íƒí•˜ì„¸ìš”", list(range(1, len(cropped_faces) + 1)))
    selected = cropped_faces[selected_face - 1]

    selected_face_image = Image.fromarray(selected)
    st.markdown("#### âœ… ì„ íƒí•œ ì–¼êµ´ ë¯¸ë¦¬ë³´ê¸°")
    st.image(selected_face_image, caption=f"ì„ íƒí•œ ì–¼êµ´ #{selected_face}", use_container_width=True)

    if selected.shape[0] < 50 or selected.shape[1] < 50:
        st.warning("ê°ì§€ëœ ì–¼êµ´ì´ ë„ˆë¬´ ìž‘ì•„ í’ˆì§ˆì´ ë–¨ì–´ì§ˆ ìˆ˜ ìžˆì–´ìš” ðŸ˜…")

    if st.button("ðŸ“¸ ì¦ëª…ì‚¬ì§„ ìƒì„±í•˜ê¸° âœ¨ (ë°˜ë ¤ë™ë¬¼)"):
        prompt = (
            "A cute professional ID photo of a pet wearing a bow tie on a clean white background. "
            "Center the pet's face in a 413x531 pixel canvas, scaled to about 50% of the full size. "
            "Extend the image downward to include the shoulders and upper body. "
            "Seamlessly blend the masked area with the original fur or features."
        )
        generate_id_photo(selected_face_image, prompt, output_filename="pet_passport_photo.jpg")


# -----------------------------
# ì‚¬ëžŒ ì²˜ë¦¬
# -----------------------------
def process_human(image):
    image_np = np.array(image)

    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
    gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

    if len(faces) == 0:
        st.warning("ì‚¬ëžŒ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆì–´ìš” ðŸ˜¢")
        return

    st.subheader("ì¸ì‹ëœ ì–¼êµ´ì„ ì„ íƒí•˜ì„¸ìš”")
    selected_index = st.radio("ì–¼êµ´ ì„ íƒ", list(range(len(faces))), horizontal=True)
    x, y, w, h = faces[selected_index]

    cropped_face = image_np[y - int(h * 0.3): y + int(h * 1.2), x - int(w * 0.1): x + int(w * 1.1)]
    cropped_face_pil = Image.fromarray(cropped_face)

    st.image(cropped_face_pil, caption="ì„ íƒëœ ì–¼êµ´", use_container_width=True)

    if cropped_face.shape[0] < 50 or cropped_face.shape[1] < 50:
        st.warning("ê°ì§€ëœ ì–¼êµ´ì´ ë„ˆë¬´ ìž‘ì•„ í’ˆì§ˆì´ ë–¨ì–´ì§ˆ ìˆ˜ ìžˆì–´ìš” ðŸ˜…")

    if st.button("ðŸ“¸ ì¦ëª…ì‚¬ì§„ ìƒì„±í•˜ê¸° âœ¨ (ì‚¬ëžŒ)"):
        prompt = (
            "Center the masked person's face in a 413x531 pixel canvas, scaled to about 50% of the full size. "
            "Extend the image downward to include the shoulders and upper body. Apply light, natural makeup in bright tones. "
            "Seamlessly blend the masked hair area with the original hairstyle. Dress the person in a formal outfit appropriate for their gender. "
            "Use a clean white background."
        )
        generate_id_photo(cropped_face_pil, prompt, output_filename="passport_photo.jpg")


# -----------------------------
# ë©”ì¸ ì‹¤í–‰
# -----------------------------
if uploaded_file:
    try:
        image = Image.open(uploaded_file).convert("RGB")
        st.markdown("### ðŸ–¼ï¸ ì›ë³¸ ì´ë¯¸ì§€")
        st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)

        if target == "ì‚¬ëžŒ":
            process_human(image)
        elif target == "ê°•ì•„ì§€/ê³ ì–‘ì´":
            process_pet(image, model_choice=model_choice)

    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
if uploaded_file:
    try:
        image = Image.open(uploaded_file).convert("RGB")

        if target == "ì‚¬ëžŒ":
            process_human(image)
        else:
            st.warning("í˜„ìž¬ ë°˜ë ¤ë™ë¬¼ ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ìž…ë‹ˆë‹¤!")

    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
else:
    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì • í›„ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
